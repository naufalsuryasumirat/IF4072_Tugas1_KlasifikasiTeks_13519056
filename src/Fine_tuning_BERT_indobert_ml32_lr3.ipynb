{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning BERT - Naufal Yahya Kurnianto 13519141"
      ],
      "metadata": {
        "id": "VHKvw_LsknOg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeCUxlaZkivW",
        "outputId": "ea833882-8286-4776-b17c-e10f06806f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM, BertModel, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o data_worthcheck.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igMzCZVUojRe",
        "outputId": "6b3a4f6c-87cb-45e6-dafe-41b309a24252"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data_worthcheck.zip\n",
            "  inflating: data_worthcheck/labels.txt  \n",
            "  inflating: data_worthcheck/dev.csv  \n",
            "  inflating: data_worthcheck/check.py  \n",
            "  inflating: data_worthcheck/train.csv  \n",
            "  inflating: data_worthcheck/test.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data_worthcheck/dev.csv "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqMGJw33or4P",
        "outputId": "bc8d67d9-7504-4f6e-b414-20581cf7492b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_a,label\n",
            "jek dajal ga depok bang,no\n",
            "detikcom untung depok masuk wilayah nya ridwan kamil kalo masuk wilayah nya anis abis lu bully ama buzzer kolam,no\n",
            "df dom jakarta depok yg gunain vc cabang nya cabang yg tercantum pas kesana gabisa bayar pake shopeepay,no\n",
            "your2rl depok jkt,no\n",
            "doakan indonesia selamat virus corona pkb depok gelar nusantara bershalawat,yes\n",
            "warga depok terganggu isu corona,yes\n",
            "kenapaa mendengar kabar salah wni positif corona depok dimana tinggal ku ku kawatir takut,yes\n",
            "hug f cibinong bogor depok ga makan siang bareng m24,no\n",
            "mukenahhh tlongggg ak maw hp ak kentank bingits sdh kebelah hadiah ultah hshs ak depok btw follback yh,no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data_worthcheck/train.csv "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpnvmD0qo2M6",
        "outputId": "198b8f3b-27bc-4f64-833c-859e829c4ca7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",text_a,label\n",
            "0,betewe buka twitter cuman ngetweet liat home berita corona panik kepikiran ndamau buka2 home yg aware aja i ll stay at home nda rumah kalo nda penting2 banget,no\n",
            "1,mas piyuuu mugo2 corona tuh mulut tersumpal ma corona,no\n",
            "2,e100ss gini buka informasi sejelas nya identitas daerah penderita terjangkit infokan masyarakat mengisolasi nya kontak langsung penderita positif corona ditutup tutupi,yes\n",
            "3,neng solo wes ono terduga corona cobo neng ati mu neng conora,no\n",
            "4,midiahn nii akun gak takut takut nya isu corona wkwkwkw,no\n",
            "5,hey corona prrgi sna,no\n",
            "6,gara corona masuk ketempat aja mesti scan jidat gw kek jajanan indomaret,no\n",
            "7,jokowi menteri2 nya silakan tes corona,yes\n",
            "8,pencegahan corona other moms minum multivitamin my mom minum rebusan sambiloto,yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data_worthcheck/test.csv "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13RrWBiYo2gx",
        "outputId": "c3e3ee3e-c3e9-457a-cb2f-d52aa12c862d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_a,label\n",
            "jek dajal ga depok bang,no\n",
            "detikcom untung depok masuk wilayah nya ridwan kamil kalo masuk wilayah nya anis abis lu bully ama buzzer kolam,no\n",
            "df dom jakarta depok yg gunain vc cabang nya cabang yg tercantum pas kesana gabisa bayar pake shopeepay,no\n",
            "your2rl depok jkt,no\n",
            "doakan indonesia selamat virus corona pkb depok gelar nusantara bershalawat,yes\n",
            "warga depok terganggu isu corona,yes\n",
            "kenapaa mendengar kabar salah wni positif corona depok dimana tinggal ku ku kawatir takut,yes\n",
            "hug f cibinong bogor depok ga makan siang bareng m24,no\n",
            "mukenahhh tlongggg ak maw hp ak kentank bingits sdh kebelah hadiah ultah hshs ak depok btw follback yh,no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'data_worthcheck/train.csv'\n",
        "df = pd.DataFrame({'label':int(), 'text':str()}, index = [])\n",
        "i = 0\n",
        "with open(file_path) as f:\n",
        "  next(f)\n",
        "  for line in f.readlines():\n",
        "    split = line.split(',')\n",
        "    df = df.append({'label': 1 if split[2] == 'yes\\n' else 0,\n",
        "                    'text': split[1]},\n",
        "                    ignore_index = True)\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "g47p7c6ypOGR",
        "outputId": "9a62b577-c1b2-4671-cd3f-c4a9c64f8420"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  betewe buka twitter cuman ngetweet liat home b...\n",
              "1      0  mas piyuuu mugo2 corona tuh mulut tersumpal ma...\n",
              "2      1  e100ss gini buka informasi sejelas nya identit...\n",
              "3      0  neng solo wes ono terduga corona cobo neng ati...\n",
              "4      0  midiahn nii akun gak takut takut nya isu coron...\n",
              "5      0                               hey corona prrgi sna\n",
              "6      0  gara corona masuk ketempat aja mesti scan jida...\n",
              "7      1             jokowi menteri2 nya silakan tes corona\n",
              "8      1  pencegahan corona other moms minum multivitami...\n",
              "9      0  mamaciaaa mnrut gue jngan dkt2 corona cb dkt y..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e5c9882-b9b4-4e44-9162-a5cad7cc191d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>betewe buka twitter cuman ngetweet liat home b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>mas piyuuu mugo2 corona tuh mulut tersumpal ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>e100ss gini buka informasi sejelas nya identit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>neng solo wes ono terduga corona cobo neng ati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>midiahn nii akun gak takut takut nya isu coron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>hey corona prrgi sna</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>gara corona masuk ketempat aja mesti scan jida...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>jokowi menteri2 nya silakan tes corona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>pencegahan corona other moms minum multivitami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>mamaciaaa mnrut gue jngan dkt2 corona cb dkt y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e5c9882-b9b4-4e44-9162-a5cad7cc191d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e5c9882-b9b4-4e44-9162-a5cad7cc191d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e5c9882-b9b4-4e44-9162-a5cad7cc191d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = df.text.values\n",
        "labels = df.label.values"
      ],
      "metadata": {
        "id": "o8Nsnkl1r67s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'indobenchmark/indobert-base-p1',\n",
        "    do_lower_case = True\n",
        "    )\n",
        "\n",
        "def print_rand_sentence():\n",
        "  '''Displays the tokens and respective IDs of a random text sample'''\n",
        "  index = random.randint(0, len(text)-1)\n",
        "  table = np.array([tokenizer.tokenize(text[index]), \n",
        "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
        "  print(tabulate(table,\n",
        "                 headers = ['Tokens', 'Token IDs'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence()"
      ],
      "metadata": {
        "id": "XmqgiT4AsGky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1eb1c2-0c97-4499-cdee-465f4ecd0829"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════════════╤═════════════╕\n",
            "│ Tokens      │   Token IDs │\n",
            "╞═════════════╪═════════════╡\n",
            "│ nes         │       24995 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##sie       │       28157 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##jud       │       28256 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##ge        │        2731 │\n",
            "├─────────────┼─────────────┤\n",
            "│ kalo        │        1686 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ka          │        1187 │\n",
            "├─────────────┼─────────────┤\n",
            "│ bah         │         168 │\n",
            "├─────────────┼─────────────┤\n",
            "│ dibersihkan │       10364 │\n",
            "├─────────────┼─────────────┤\n",
            "│ info        │        1617 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ditutup     │        5819 │\n",
            "├─────────────┼─────────────┤\n",
            "│ sampe       │        5985 │\n",
            "├─────────────┼─────────────┤\n",
            "│ wk          │       20181 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##tu        │          33 │\n",
            "├─────────────┼─────────────┤\n",
            "│ yg          │         741 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ditentukan  │        3835 │\n",
            "├─────────────┼─────────────┤\n",
            "│ semoga      │        1671 │\n",
            "├─────────────┼─────────────┤\n",
            "│ aja         │        1465 │\n",
            "├─────────────┼─────────────┤\n",
            "│ konspirasi  │       22052 │\n",
            "├─────────────┼─────────────┤\n",
            "│ jepang      │        1794 │\n",
            "├─────────────┼─────────────┤\n",
            "│ sholat      │        5458 │\n",
            "├─────────────┼─────────────┤\n",
            "│ jumat       │        3253 │\n",
            "├─────────────┼─────────────┤\n",
            "│ diti        │       18875 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##adakan    │        2551 │\n",
            "├─────────────┼─────────────┤\n",
            "│ baca        │        2064 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##2         │       30378 │\n",
            "├─────────────┼─────────────┤\n",
            "│ theory      │       21490 │\n",
            "├─────────────┼─────────────┤\n",
            "│ konspirasi  │       22052 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ttg         │       11824 │\n",
            "├─────────────┼─────────────┤\n",
            "│ cor         │        3021 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##ona       │        2524 │\n",
            "├─────────────┼─────────────┤\n",
            "│ berkembang  │        2016 │\n",
            "├─────────────┼─────────────┤\n",
            "│ facebook    │        2861 │\n",
            "├─────────────┼─────────────┤\n",
            "│ udah        │        2137 │\n",
            "├─────────────┼─────────────┤\n",
            "│ nge         │       21968 │\n",
            "├─────────────┼─────────────┤\n",
            "│ hapus       │        5120 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##in        │          17 │\n",
            "├─────────────┼─────────────┤\n",
            "│ issue       │       28059 │\n",
            "├─────────────┼─────────────┤\n",
            "│ ##2         │       30378 │\n",
            "╘═════════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id = []\n",
        "attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  '''\n",
        "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "  '''\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 32,\n",
        "                        padding = 'max_length',\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation = True\n",
        "                   )\n",
        "\n",
        "\n",
        "for sample in text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids']) \n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "Z9TQ9-tHtk93"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence_encoding():\n",
        "  '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
        "  index = random.randint(0, len(text) - 1)\n",
        "  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
        "  token_ids = [i.numpy() for i in token_id[index]]\n",
        "  attention = [i.numpy() for i in attention_masks[index]]\n",
        "\n",
        "  table = np.array([tokens, token_ids, attention]).T\n",
        "  print(tabulate(table, \n",
        "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence_encoding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTeFDSc41E_z",
        "outputId": "47b352f6-8c22-45a0-bb06-df32cbd7704f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════════╤═════════════╤══════════════════╕\n",
            "│ Tokens     │   Token IDs │   Attention Mask │\n",
            "╞════════════╪═════════════╪══════════════════╡\n",
            "│ [CLS]      │           2 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ presiden   │        1871 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ tegaskan   │       28072 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ serius     │        3934 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ tangani    │       18683 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ wabah      │       18465 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ cor        │        3021 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ##ona      │        2524 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ jakarta    │         678 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ https      │       14012 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ t          │          18 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ co         │        2108 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ x          │         921 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ##az       │        4476 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ##oz       │       15308 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ##zy       │       12966 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ##va       │        4642 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ##e        │       30357 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ak         │         228 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ presiden   │        1871 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ joko       │        8151 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ widodo     │       10505 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ pemerintah │         877 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ mengambil  │        1632 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ langkah    │        1775 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ pencegahan │        6527 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ serta      │         501 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ##a        │       30354 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ ak         │         228 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ https      │       14012 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ t          │          18 │                1 │\n",
            "├────────────┼─────────────┼──────────────────┤\n",
            "│ [SEP]      │           3 │                1 │\n",
            "╘════════════╧═════════════╧══════════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ratio = 0.2\n",
        "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "batch_size = 16\n",
        "\n",
        "# Indices of the train and validation splits stratified by labels\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(labels)),\n",
        "    test_size = val_ratio,\n",
        "    shuffle = True,\n",
        "    stratify = labels)\n",
        "\n",
        "# Train and validation sets\n",
        "train_set = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          labels[train_idx])\n",
        "\n",
        "val_set = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        labels[val_idx])\n",
        "\n",
        "# Prepare DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "            train_set,\n",
        "            sampler = RandomSampler(train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_set,\n",
        "            sampler = SequentialSampler(val_set),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "nAtOkpRBznNT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "metadata": {
        "id": "9Wj3qwVXB44i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = AutoModel.from_pretrained(\n",
        "#     \"indolem/indobert-base-uncased\",\n",
        "#     num_labels = 2,\n",
        "#     output_attentions = False,\n",
        "#     output_hidden_states = False,\n",
        "# )\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained (\n",
        "    \"indobenchmark/indobert-base-p1\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# model = BertModel.from_pretrained (\n",
        "#     \"bert-base-multilingual-uncased\",\n",
        "#     num_labels = 2,\n",
        "#     output_attentions = False,\n",
        "#     output_hidden_states = False,\n",
        "# )\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                              lr = 3e-5,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "# Run on GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtnt_396CBUa",
        "outputId": "48d76d7a-e1a1-4fec-c2f5-12111c0654c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "epochs = 2\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    \n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += train_output.loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf3PJeaSCOEn",
        "outputId": "d42e6d38-f7a2-4994-aed5-9975f4ae9875"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  50%|█████     | 1/2 [02:22<02:22, 142.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.2988\n",
            "\t - Validation Accuracy: 0.9031\n",
            "\t - Validation Precision: 0.8421\n",
            "\t - Validation Recall: 0.8198\n",
            "\t - Validation Specificity: 0.9379\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 2/2 [04:47<00:00, 143.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.1798\n",
            "\t - Validation Accuracy: 0.9018\n",
            "\t - Validation Precision: 0.7918\n",
            "\t - Validation Recall: 0.8882\n",
            "\t - Validation Specificity: 0.9060\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'data_worthcheck/test.csv'\n",
        "df_testval = pd.DataFrame({'label':int(), 'text':str()}, index = [])\n",
        "with open(file_path) as f:\n",
        "  next(f)\n",
        "  for line in f.readlines():\n",
        "    split = line.split(',')\n",
        "    # if (len(split[0])>1024):\n",
        "    #   continue\n",
        "    df_testval = df_testval.append({'label': 1 if split[1] == 'yes\\n' else 0,\n",
        "                    'text': split[0]},\n",
        "                    ignore_index = True)\n",
        "\n",
        "df_test = pd.DataFrame({'label':int(), 'text':str()}, index = [])\n",
        "with open(file_path) as f:\n",
        "  next(f)\n",
        "  for line in f.readlines():\n",
        "    split = line.split(',')\n",
        "    # if (len(split[0])>1024):\n",
        "    #   continue\n",
        "    test_ids = []\n",
        "    test_attention_mask = []\n",
        "\n",
        "    # Apply the tokenizer\n",
        "    encoding = preprocessing(split[0], tokenizer)\n",
        "\n",
        "    # Extract IDs and Attention Mask\n",
        "    test_ids.append(encoding['input_ids'])\n",
        "    test_attention_mask.append(encoding['attention_mask'])\n",
        "    test_ids = torch.cat(test_ids, dim = 0)\n",
        "    test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "\n",
        "    # Forward pass, calculate logit predictions\n",
        "    with torch.no_grad():\n",
        "      output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
        "\n",
        "    prediction = 'yes' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'no'\n",
        "\n",
        "    df_test = df_test.append({'label': 1 if prediction == 'yes' else 0,\n",
        "                    'text': split[0]},\n",
        "                    ignore_index = True)\n",
        "\n",
        "# # We need Token IDs and Attention Mask for inference on the new sentence\n",
        "# test_ids = []\n",
        "# test_attention_mask = []\n",
        "\n",
        "# # Apply the tokenizer\n",
        "# encoding = preprocessing(new_sentence, tokenizer)\n",
        "\n",
        "# # Extract IDs and Attention Mask\n",
        "# test_ids.append(encoding['input_ids'])\n",
        "# test_attention_mask.append(encoding['attention_mask'])\n",
        "# test_ids = torch.cat(test_ids, dim = 0)\n",
        "# test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "\n",
        "# # Forward pass, calculate logit predictions\n",
        "# with torch.no_grad():\n",
        "#   output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
        "\n",
        "# prediction = 'yes' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'no'\n",
        "\n",
        "df_testval.head(100)\n",
        "df_test.head(100)"
      ],
      "metadata": {
        "id": "lf3GIexMZBqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0f035308-87c2-4db0-f1fb-0831e9695424"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                               text\n",
              "0       0                            jek dajal ga depok bang\n",
              "1       1  detikcom untung depok masuk wilayah nya ridwan...\n",
              "2       0  df dom jakarta depok yg gunain vc cabang nya c...\n",
              "3       0                                  your2rl depok jkt\n",
              "4       1  doakan indonesia selamat virus corona pkb depo...\n",
              "..    ...                                                ...\n",
              "95      0  jrantesalu8 aniesbaswedan permadiaktivis gunro...\n",
              "96      0  sebener nya gua panik bgt pdhl td lg joke ttg ...\n",
              "97      0           udah bercandain corona tunggu terjangkit\n",
              "98      0  meremehkan tindakan2 pemberitaan pengen tau aj...\n",
              "99      1  pelaporan spt online sebener nya salah langkah...\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7da5f4b1-8154-4eff-b1eb-ff797f8d1665\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>jek dajal ga depok bang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>detikcom untung depok masuk wilayah nya ridwan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>df dom jakarta depok yg gunain vc cabang nya c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>your2rl depok jkt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>doakan indonesia selamat virus corona pkb depo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0</td>\n",
              "      <td>jrantesalu8 aniesbaswedan permadiaktivis gunro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0</td>\n",
              "      <td>sebener nya gua panik bgt pdhl td lg joke ttg ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "      <td>udah bercandain corona tunggu terjangkit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0</td>\n",
              "      <td>meremehkan tindakan2 pemberitaan pengen tau aj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "      <td>pelaporan spt online sebener nya salah langkah...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7da5f4b1-8154-4eff-b1eb-ff797f8d1665')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7da5f4b1-8154-4eff-b1eb-ff797f8d1665 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7da5f4b1-8154-4eff-b1eb-ff797f8d1665');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"%.2f\" % (100-len(df_test.compare(df_testval))/len(df_testval)*100) + \" % classification correct\")"
      ],
      "metadata": {
        "id": "5Y6Klr_idC_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0926b13e-aded-4fdf-c072-1ec96b3634b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85.89 % classification correct\n"
          ]
        }
      ]
    }
  ]
}